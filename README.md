<h1 align="center">ğŸ¤– RTTSSL</h1>
   <h2 align="center">Real-Time Translation System for Sign Language</h2>
      <p align="center">RTTSSL is a Python-based system designed to visually translate letters, words and gestures in real time.</p>
  <a href="https://github.com/JDs2019sk/RTTSSL/blob/main/LICENSE">
    <img src="https://img.shields.io/badge/License-MIT-green?style=flat-square" alt="MIT License">
  </a>
## ğŸ’¡ Features

- ğŸ¤Ÿ Real-time gesture recognition and translation
- ğŸ†— Sign language letter and word detection
- ğŸ˜‘ Facial Recognition
- ğŸ’¾ Model training capabilities
- ğŸ¥ Recording method for your translations
- ğŸ“Š Performance monitoring and optimization

## ğŸ”¤ Requirements

- Python 3.8-3.11 (TensorFlow compatibility)
- Webcam
- Required packages listed in `requirements.txt`
- GPU is recommended for faster training

## ğŸ› ï¸ Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/JDs2019sk/RTTSSL.git
   cd RTTSSL
   ```

2. Create and activate a virtual environment (recommended):

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. Install required packages:
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ“š Usage

1. Test your camera setup:

   ```bash
   python test_camera.py
   ```

2. Test your GPU:

   ```bash
   python test_gpu.py
   ```

3. Train the gesture recognition model:

   ```bash
   python -m src.gesture.model_trainer
   ```

See [Training file](docs/TRAINING.md) for detailed training instructions.

4. Run the main program:
   ```bash
   python main.py
   ```

## âŒ¨ï¸ Default Keybinds

### Main Application Controls

| Key   | Function            | Description                                     |
| ----- | ------------------- | ----------------------------------------------- |
| `1`   | Letter Mode         | Switch to sign language letter translation mode |
| `2`   | Word Mode           | Switch to sign language word translation mode   |
| `3`   | Gesture Mode        | Switch to gesture recognition mode              |
| `M`   | Mouse Control       | Toggle hand gesture mouse control               |
| `F`   | Face Detection      | Enable face detection and recognition           |
| `E`   | Toggle Face Mode    | Cycle between mesh, iris, and recognition modes |
| `Tab` | Toggle FPS          | Show/hide FPS counter                           |
| `P`   | Performance Monitor | Show/hide performance statistics                |
| `R`   | Recording           | Start/stop recording                            |
| `H`   | Help Menu           | Show help and controls overlay                  |
| `Esc` | Exit                | Close the application                           |

### Training Mode Controls

| Key | Function           | Description                                  |
| --- | ------------------ | -------------------------------------------- |
| `Q` | Quit               | Exit training mode                           |
| `N` | New Label          | Set a new label for recording                |
| `S` | Sample Recording   | Start/stop recording samples                 |
| `T` | Train Model        | Start model training (min 20, max 150/label) |
| `R` | Retrain Gesture    | Retrain a specific gesture from scratch      |
| `I` | Show Training Info | Show training information                    |

For detailed training instructions, see [Training Guide](docs/TRAINING.md).

### Camera Test Controls

| Key | Function     | Description             |
| --- | ------------ | ----------------------- |
| `Q` | Quit         | Exit camera test        |
| `S` | Save Image   | Save a test image       |
| `R` | Reset Camera | Reset camera connection |

## ğŸ“‚ Project Structure

```
RTTSSL/
â”œâ”€â”€ arduino config/       # arduino configuration folder
â”‚   â””â”€â”€ script.py         # arduino function
â”œâ”€â”€ config/               # Configuration files for the project
â”‚   â””â”€â”€ configs.yaml      # Keybinds/configs file
â”œâ”€â”€ datasets/             # Training and testing datasets
â”‚   â”œâ”€â”€ gesture/          # Images to train gestures
â”‚   â”œâ”€â”€ letter/           # Images to train letters
â”‚   â””â”€â”€ word/             # Images to train words
â”œâ”€â”€ docs/                 # Documentation
â”‚   â””â”€â”€ TRAINING.md       # Training guide
â”œâ”€â”€ logs/                 # Log files from training and execution
â”œâ”€â”€ models/               # Trained models
â”œâ”€â”€ recordings/           # Recorded video files
â”œâ”€â”€ src/                  # Source code directory
â”‚   â”œâ”€â”€ face/             # Face detection modules
â”‚   â”œâ”€â”€ gesture/          # Gesture recognition modules
â”‚   â”œâ”€â”€ mouse/            # Mouse control modules
â”‚   â””â”€â”€ utils/            # Utility functions
â”œâ”€â”€ test_images/          # Images taken in camera test
â”œâ”€â”€ main.py               # Main application entry point
â”œâ”€â”€ requirements.txt      # Package dependencies
â”œâ”€â”€ test_camera.py        # Camera testing utility
â””â”€â”€ gpu_test.py           # GPU test for performance tracking (NVIDIA only)
```

#### Some folders will not be present, but they will be created by executing the program. [`data/ datasets/ logs/ models/ recordings/ faces/ test_images`]

## ğŸ‘ Created by Joel Dias (PAP 24/25)
