# ğŸ¤– RTTSSL - Real-Time Translation System for Sign Language

RTTSSL is a Python-based system designed to visually translate letters, words and gestures in real time.

## ğŸ’¡ Features

- Real-time gesture recognition and translation
- Sign language letter and word detection
- Advanced facial detection:
  - Face mesh detection
  - Eye iris tracking
  - Face recognition with name assignment
- Real-time model training capabilities
- Record your Translations
- Automatic model versioning and backup

## ğŸ”¤ Requirements

- Python 3.8-3.11 (TensorFlow compatibility)
- Webcam with good resolution
- Required packages listed in `requirements.txt`
- GPU recommended for faster training

## ğŸ› ï¸ Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/JDs2019sk/RTTSSL.git
   cd RTTSSL
   ```

2. Create and activate a virtual environment (recommended):

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. Install required packages:
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ“š Usage

1. Test your camera setup:

   ```bash
   python test_camera.py
   ```

2. Train the gesture recognition model:

   ```bash
   python -m src.gesture.model_trainer
   ```

See [Training file](docs/TRAINING.md) for detailed training instructions.

3. Run the main program:
   ```bash
   python main.py
   ```

## ğŸ“‚ Project Structure

```
RTTSSL/
â”œâ”€â”€ config                # Configuration files for the project
â”‚   â””â”€â”€ keybinds.yaml     # keybinds/config file
â”œâ”€â”€ data                  # Raw and processed data storage
â”œâ”€â”€ datasets              # Training and testing datasets
â”œâ”€â”€ docs/                 # Documentation
â”‚   â””â”€â”€ TRAINING.md       # Training guide
â”œâ”€â”€ logs                  # Log files from training and execution
â”œâ”€â”€ models/               # Trained models
â”œâ”€â”€ recordings            # Recorded video files
â”œâ”€â”€ src/                  # Source code directory
â”‚   â”œâ”€â”€ gesture/          # Gesture recognition modules
â”‚   â”œâ”€â”€ face/             # Face detection modules
â”‚   â””â”€â”€ utils/            # Utility functions
â”œâ”€â”€ main.py               # Main application entry point
â”œâ”€â”€ requirements.txt      # Package dependencies
â”œâ”€â”€ test_camera.py        # Camera testing utility
â””â”€â”€ train.py              # Model training script
```

#### Some folders will not be present, but they will be created by executing the program. [`data/ datasets/ logs/ models/ recordings/`]

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- MediaPipe for hand landmark detection
- TensorFlow and Keras teams
- OpenCV community
